# MHA2MLA


This repo builds on the paper's Repo ["Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs"](https://arxiv.org/abs/2502.14837). Here we have implemented randomized SVD variant of the MHA2MLA pipeline and implemented several experiment suites.



![alt text](img/overview.png)


